{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:40:01.760358200Z",
     "start_time": "2024-05-29T13:39:56.418871Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import numpy as np\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6953cbd0edb1341",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:40:15.166670200Z",
     "start_time": "2024-05-29T13:40:01.766354300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers={\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36 \"}\n",
    "plot_summeries = []\n",
    "def get_plot(url):\n",
    "    with requests.Session() as session:\n",
    "        plot = session.get(url,headers=headers)\n",
    "        plot_soup = bs4.BeautifulSoup(plot.text,\"html.parser\")\n",
    "        plots = plot_soup.find_all(\"div\",{\"class\" : \"ipc-html-content-inner-div\"})\n",
    "        plot = plots[0].text\n",
    "        plot_summeries.append(plot)\n",
    "page = requests.get(\"https://www.imdb.com/chart/top/\", headers=headers)\n",
    "soup = bs4.BeautifulSoup(page.text, \"html.parser\")\n",
    "names = soup.find_all(\"div\",{\"class\" : \"ipc-title ipc-title--base ipc-title--title ipc-title-link-no-icon ipc-title--on-textPrimary sc-b189961a-9 iALATN cli-title\"})\n",
    "infos = soup.find_all(\"span\" , {\"class\" : \"sc-b189961a-8 kLaxqf cli-title-metadata-item\"})\n",
    "links = str(soup.find_all(\"a\", {\"class\" : \"ipc-title-link-wrapper\"})).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f09600589c351155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:40:15.198420400Z",
     "start_time": "2024-05-29T13:40:15.162139800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for item in links:\n",
    "    if 'href=' not in item:\n",
    "        links.remove(item)\n",
    "final_links = []\n",
    "for item in links:\n",
    "    if 'href=' in item:\n",
    "        final_links.append((item.split('href=\"')[1]).split('?ref_=')[0])\n",
    "final_links = final_links[:-7]\n",
    "for i in range(len(final_links)):\n",
    "    junked = list(final_links[i])\n",
    "    junked = ['https://www.imdb.com']+junked\n",
    "    junked = junked + ['plotsummary/?ref_=tt_stry_pl']\n",
    "    final_links[i]=''.join(junked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f84e5a29a03ba5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:40:15.252090Z",
     "start_time": "2024-05-29T13:40:15.205416200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies_name = []\n",
    "movies_year = []\n",
    "for i in names:\n",
    "    name = i.text\n",
    "    movies_name.append(name.split('. ')[1])\n",
    "for i in range(len(infos)):\n",
    "    infos[i]=infos[i].text\n",
    "for i in range(len(infos)):\n",
    "    if infos[i].isnumeric():\n",
    "        if infos[i+2].isnumeric():\n",
    "            infos.insert(i+2,\"Not Rated\")\n",
    "for j in range(0,len(infos)-2,3):\n",
    "    year = [movies_name[j//3],infos[j], infos[j+1], infos[j+2],final_links[j//3]]\n",
    "    movies_year.append(year)\n",
    "movies_year = np.array(movies_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e60ef50065d966",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-29T13:40:15.261084500Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "for url in final_links:\n",
    "    get_plot(url)\n",
    "with open(\"plot_summeries.txt\" , \"w+\") as f:\n",
    "    for plot in plot_summeries:\n",
    "        f.write(plot)\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"____________________________________________________\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c71e1dcb1abe0e",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "infile = \"plot_summeries.txt\"\n",
    "outfile = \"cleaned_file.txt\"\n",
    "delete_list = stopwords.words('english')\n",
    "delete_sen = r'\\b' + r'\\b|\\b'.join(delete_list) + r'\\b'\n",
    "with open(infile) as fin, open(outfile, \"w+\") as fout:\n",
    "    lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        new_line = re.sub(f'(?!\\w*\\..\\w*|\\w*\\..\\w*\\..\\w*)({delete_sen})', \"\", line.lower())\n",
    "        fout.write(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc31dddb806d310d",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "with open(\"cleaned_file.txt\",\"r\") as f  :\n",
    "    text = f.read()\n",
    "    docs = text.split('\\n____________________________________________________\\n')[:-1]\n",
    "    for doc in docs:\n",
    "        doc = doc.split()\n",
    "        for word in doc:\n",
    "            words.append(word)\n",
    "words = set(words)\n",
    "TF_values = []\n",
    "for doc in docs:\n",
    "    dic = []\n",
    "    doc = doc.split()\n",
    "    for word in words:\n",
    "        dic.append(doc.count(word)/len(doc))\n",
    "    TF_values.append(dic)\n",
    "IDF_dict = []\n",
    "for word in words:\n",
    "    word_counter = 0\n",
    "    for doc in docs:\n",
    "        if word in doc:\n",
    "            word_counter+=1\n",
    "    IDF_dict.append(math.log(len(docs)/word_counter) + 1)\n",
    "for dict in TF_values:\n",
    "    for i in range(len(dict)):\n",
    "        dict[i] = dict[i] * IDF_dict[i]\n",
    "query = re.sub(f'(?!\\w*\\..\\w*|\\w*\\..\\w*\\..\\w*)({delete_sen})', \"\", input('Enter your film plot summery').lower()).split()\n",
    "TF_query = []\n",
    "for word in words:\n",
    "    TF_query.append(query.count(word)/len(query))\n",
    "IDF_query = []\n",
    "for word in words:\n",
    "    IDF_query.append(math.log(len(query)) + 1)\n",
    "for i in range(len(TF_query)):\n",
    "    TF_query[i] = TF_query[i] * IDF_query[i]\n",
    "TF_query = np.array(TF_query)\n",
    "cosine_similarity = []\n",
    "for item in TF_values:\n",
    "    wanted_vector = np.array(item)\n",
    "    cosine_similarity.append(np.inner(wanted_vector, TF_query)/((np.inner(wanted_vector,wanted_vector)**0.5)*(np.inner(TF_query,TF_query)**0.5)))\n",
    "for i in range(5):\n",
    "    print(cosine_similarity.index(max(cosine_similarity))+1,'.',movies_name[cosine_similarity.index(max(cosine_similarity))])\n",
    "    cosine_similarity[cosine_similarity.index(max(cosine_similarity))] = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
